大O表示法指出了算法运行时间的增速，说的是最糟糕的情景

从快到慢的顺序列出了你经常会遇到的5种大O运行时间

O(log n)

O(n)

O(n*log n)

O(n^2^)

O(n!)



数组与链表的对比。

本质区别：数组存储大小固定，位置紧靠；链表存储大小可调，位置随机，下一个位置存储在上一个元素中。

而这样的区别意味着链表在读取所有元素时效率很高，同时插入元素很方表；数组在随机访问时效率很高。

<img src="D:\research_workshop_new\算法\learn\算法.assets\image-20210310213443678.png" alt="image-20210310213443678" style="zoom: 33%;" />



递归

递归只是让解决方案更清晰，并没有性能上的优势，实际上，使用循环的性能更好。

使用递归时必须要告诉程序什么时候结束。这个停止递归的条件称为基线条件。



栈和调用栈

栈有压入和弹出，而我们调用函数相当于我们压入一个函数，而弹出时后压入的先弹出，栈帮助你跟踪函数，但是同时使用的内存也比较大了。

分而治之(divide and conquer)是一种解决递归问题的思想方法。

工作原理就是1.找出简单的基线条件    2.确定如何缩小问题的规模，使其符合基线条件。

##快速排序##

快速排序内容比较多，这里只记录关键信息，看不明白再去看算法图解。

快速排序是典型的分而治之的应用。

步骤如下：

1.选择基准值

2.将数组分为两个子数组，小于基准值和大于

3.对这两个子数组进行快速排序也就是再从1开始。

调用栈高度不一样导致存在最好情况和最差情况

快速排序平均运行时间是O(n) * O(log n) (这部分是调用栈高度)= O(n log n)



此外在这部分还讲了大O计时法。不考虑常量是因为如果两种算法的大O运行时间不同，常量不重要。

但有时候时间常量有时候不能忽略-例如快速查找和合并查找，快速查找常量比合并查找小，如果运行时间都是O(n log n)，那快速查找更快。

##散列表##

散列表是基本数据结构之一

散列函数完成的作用是将输入映射为数字，最好是不同的数字。

散列函数知道数组有多大，只返回有效的索引，如果数组包含5个元素，散列函数就不会返回无效索引100。

散列表使用散列函数来确定元素的存储位置。

获取元素的速度和数组一样快。

python提供的散列表实现为字典，可以用dict来创建。

散列表常见应用：大海捞针的查找，防止重复

